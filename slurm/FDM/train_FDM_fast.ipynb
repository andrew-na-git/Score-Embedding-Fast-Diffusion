{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import threading\n",
    "import torch.multiprocessing as multiprocessing\n",
    "import time\n",
    "import functools\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "import scipy.stats as stats\n",
    "\n",
    "from utils.kfp import get_B_block, diffusion_coeff, solve_pde, get_sparse_A_block, marginal_prob_std\n",
    "from network.network import ScoreNet\n",
    "\n",
    "from data.Dataset import CIFARDataset\n",
    "\n",
    "torch.manual_seed(2);\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change these\n",
    "N = 20\n",
    "H = 28\n",
    "W = 28\n",
    "epochs = 1000\n",
    "sigma = 2\n",
    "lr = 1e-4\n",
    "###\n",
    "\n",
    "eps = 1e-6\n",
    "dt = 1/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "marginal_prob_std_fn = functools.partial(marginal_prob_std, sigma=sigma)\n",
    "diffusion_coeff_fn = functools.partial(diffusion_coeff, sigma=sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = CIFARDataset(W, H);\n",
    "\n",
    "channels = dataset.channels\n",
    "n_data = len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create memory buffers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.zeros((N, channels, H*W), dtype=np.float32)\n",
    "m_prev = np.ones((N, channels, H*W), dtype=np.float32)\n",
    "scores = np.ones((N, channels, H*W), dtype=np.float32) # initial scores guess\n",
    "dm = np.zeros_like(scores, dtype=np.float32)\n",
    "\n",
    "# we want to sample from random time steps to construct training samples\n",
    "time_ = np.linspace(eps, 1, N).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Defining pde diffusion for multi-threading\n",
    "def diffuse(x, m, dm, channel, time_, g, scores):\n",
    "\n",
    "  y_train = []\n",
    "  for j in range(H):\n",
    "    y_train.append(x[channel][j, :])\n",
    "  y_train = np.concatenate(y_train)\n",
    "  print(y_train.shape)\n",
    "  x_train = []\n",
    "  for l in range(W):\n",
    "    x_train.append(x[channel][:, l])\n",
    "  x_train = np.concatenate(x_train)\n",
    "\n",
    "  xy_train = np.vstack([x_train, y_train])\n",
    "  kde_kernel = stats.gaussian_kde(xy_train)\n",
    "  xy_sample = kde_kernel.resample(seed=0)\n",
    "  m[0, channel] = kde_kernel.logpdf(xy_train)\n",
    "  dx = xy_train.max()/H*W\n",
    "  \n",
    "  sparse_A_block = get_sparse_A_block(dx, dt, g(time_[1:]), scores[1:, channel], H, W, N)\n",
    "\n",
    "  B_block = get_B_block(dx, dt, m, channel, H, W, N)\n",
    "\n",
    "  m[1:, channel] = solve_pde(sparse_A_block, B_block, mode='sp_sparse').reshape((-1, H*W))\n",
    "  img_log_prob = m[:, channel]\n",
    "  for i in range(N):\n",
    "    dm[i, channel, 1:-1] = (img_log_prob[i,:-2] - img_log_prob[i,2:])/(2*dx)\n",
    "    dm[i, channel, 0] = dm[i, channel, 1]\n",
    "    dm[i, channel, -1] = dm[i, channel, -2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n",
      "(19, 784)\n",
      "(784,)\n",
      "(19, 784)\n",
      "(784,)\n",
      "(19, 784)\n",
      "residual at iteration 0: 0.8277451395988464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n",
      "(19, 784)\n",
      "(784,)\n",
      "(19, 784)\n",
      "(784,)\n",
      "(19, 784)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "residual at iteration 1: 0.1410660594701767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n",
      "(19, 784)\n",
      "(784,)\n",
      "(19, 784)\n",
      "(784,)\n",
      "(19, 784)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "residual at iteration 2: 0.008156058378517628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.95it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n",
      "(19, 784)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n",
      "(19, 784)\n",
      "(784,)\n",
      "(19, 784)\n",
      "residual at iteration 3: 0.0008493129280395806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res = 1\n",
    "e = 0\n",
    "\n",
    "while res > 0.005:\n",
    "  for idx, data in tqdm(enumerate(dataset)):\n",
    "    \n",
    "\n",
    "    # diffuse all three channels concurrently\n",
    "    for ch in range(channels):\n",
    "        diffuse(data, m, dm, ch, time_, diffusion_coeff_fn, scores)\n",
    "\n",
    "    scores = dm.copy()\n",
    "\n",
    "    if e == 1000:\n",
    "      print(f'No convergence')\n",
    "      break\n",
    "\n",
    "    res = np.linalg.norm(m - m_prev)/np.linalg.norm(m_prev)\n",
    "    print(f'residual at iteration {e}: {res}')\n",
    "\n",
    "    m_prev = m.copy()\n",
    "    e += 1\n",
    "\n",
    "scores_label = scores.copy().reshape((-1, channels, H, W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_fn(model, x, label, diffusion_coeff, marginal_prob_std, eps=1e-5):\n",
    "  \"\"\"The loss function for training score-based generative models.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model instance that represents a\n",
    "      time-dependent score-based model.\n",
    "    x: A mini-batch of training data.\n",
    "    marginal_prob_std: A function that gives the standard deviation of\n",
    "      the perturbation kernel.\n",
    "    eps: A tolerance value for numerical stability.\n",
    "  \"\"\"\n",
    "  random_t = torch.tensor(np.sort(np.random.uniform(eps, 1., N)).astype(np.float32))\n",
    "  # we encode the label into the initial data using the reverse ODE\n",
    "  diff_std2 = diffusion_coeff(2 * random_t)\n",
    "  for i in range(1, N):\n",
    "    x[i] = x[i-1] - 0.5 * label[i] * diff_std2[i] * dt\n",
    "  std = marginal_prob_std(random_t)\n",
    "  z = torch.randn_like(x)\n",
    "  # we perturb the image by the forward SDE conditional distribution\n",
    "  perturbed_x = x + z * std[:, None, None, None]\n",
    "  score = model(perturbed_x, random_t)\n",
    "  # loss = torch.mean(torch.sum((score * std[:, None, None, None] - label)**2, dim=(1, 2, 3)) / (2 * diff_std2))\n",
    "  loss = torch.mean(torch.sum((score * std[:, None, None, None] + z)**2, dim=(1, 2, 3))) # original loss from tutorial\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:04<00:00, 15.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loss at channel 1: 78.59217071533203\n",
      "model for thread 1 has been saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:07<00:00, 14.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loss at channel 2: 79.23463439941406\n",
      "model for thread 2 has been saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:08<00:00, 14.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loss at channel 0: 78.7034683227539\n",
      "model for thread 0 has been saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#@title Function for training on a thread\n",
    "def diffuse_train(channel, init_x, epoch, diffusion_coeff, marginal_prob_std, label):\n",
    "  \n",
    "  model_score = ScoreNet(marginal_prob_std=marginal_prob_std)\n",
    "  optimizer = Adam(model_score.parameters(), lr=lr)\n",
    "  model_score.train();\n",
    "\n",
    "  scores_label = torch.tensor(label)[:, channel][:, None]\n",
    "  for e in tqdm(range(epoch)):\n",
    "    loss = loss_fn(model_score, init_x[:, channel][:, None], scores_label, diffusion_coeff, marginal_prob_std)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  print(f'\\nloss at channel {channel}: {loss}')\n",
    "  file = f'model_cifar_thread_{channel}.pth'\n",
    "  torch.save(model_score.state_dict(), file)\n",
    "  print(f\"model for thread {channel} has been saved\\n\")\n",
    "\n",
    "processes = [None] * channels\n",
    "init_x = torch.zeros((N, channels, H, W))\n",
    "\n",
    "diffuse_train_fn = functools.partial(diffuse_train, init_x=init_x, epoch=epochs, diffusion_coeff = diffusion_coeff_fn, marginal_prob_std = marginal_prob_std_fn, label=scores_label)\n",
    "\n",
    "for idx, data in enumerate(dataset):\n",
    "  for ch in range(channels):\n",
    "    init_x[:, ch] = data[ch]\n",
    "\n",
    "  # train all three channels concurrently\n",
    "  for ch in range(channels):\n",
    "    processes[ch] = multiprocessing.Process(target=diffuse_train, args=[ch, init_x, epochs, diffusion_coeff_fn, marginal_prob_std_fn, scores_label])\n",
    "    processes[ch].start()\n",
    "\n",
    "  for p in processes:\n",
    "    processes.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
