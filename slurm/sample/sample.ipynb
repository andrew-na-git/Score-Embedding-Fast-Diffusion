{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "import torch\n",
    "from scipy import integrate\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import threading\n",
    "import functools\n",
    "\n",
    "sigma = 2\n",
    "\n",
    "from utils.kfp import diffusion_coeff, marginal_prob_std\n",
    "from network.network import ScoreNet\n",
    "\n",
    "marginal_prob_std_fn = functools.partial(marginal_prob_std, sigma=sigma)\n",
    "diffusion_coeff_fn = functools.partial(diffusion_coeff, sigma=sigma)\n",
    "\n",
    "\n",
    "error_tolerance = 1e-5\n",
    "\n",
    "channels = 3\n",
    "N = 20\n",
    "H = 28\n",
    "W = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The error tolerance for the black-box ODE solver\n",
    "error_tolerance = 1e-5\n",
    "def ode_sampler(score_model,\n",
    "                marginal_prob_std,\n",
    "                diffusion_coeff,\n",
    "                batch_size=64,\n",
    "                atol=error_tolerance,\n",
    "                rtol=error_tolerance,\n",
    "                device='cpu',\n",
    "                z=None,\n",
    "                eps=1e-3):\n",
    "  \"\"\"Generate samples from score-based models with black-box ODE solvers.\n",
    "\n",
    "  Args:\n",
    "    score_model: A PyTorch model that represents the time-dependent score-based model.\n",
    "    marginal_prob_std: A function that returns the standard deviation\n",
    "      of the perturbation kernel.\n",
    "    diffusion_coeff: A function that returns the diffusion coefficient of the SDE.\n",
    "    batch_size: The number of samplers to generate by calling this function once.\n",
    "    atol: Tolerance of absolute errors.\n",
    "    rtol: Tolerance of relative errors.\n",
    "    device: 'cuda' for running on GPUs, and 'cpu' for running on CPUs.\n",
    "    z: The latent code that governs the final sample. If None, we start from p_1;\n",
    "      otherwise, we start from the given z.\n",
    "    eps: The smallest time step for numerical stability.\n",
    "  \"\"\"\n",
    "  t = torch.tensor(np.linspace(1., eps, N))\n",
    "  # Create the latent code\n",
    "  if z is None:\n",
    "    initial_x = torch.randn(batch_size, 1, H, W, device=device) \\\n",
    "      * marginal_prob_std(t)[:, None, None, None]\n",
    "  else:\n",
    "    initial_x = z + torch.randn(batch_size, 1, H, W, device=device) \\\n",
    "      * marginal_prob_std(t)[:, None, None, None]\n",
    "\n",
    "  shape = initial_x.shape\n",
    "\n",
    "  def score_eval_wrapper(sample, time_steps):\n",
    "    \"\"\"A wrapper of the score-based model for use by the ODE solver.\"\"\"\n",
    "    sample = torch.tensor(sample, device=device, dtype=torch.float32).reshape(shape)\n",
    "    time_steps = torch.tensor(time_steps, device=device, dtype=torch.float32).reshape((sample.shape[0], ))\n",
    "    with torch.no_grad():\n",
    "      score = score_model(sample, time_steps)\n",
    "    return score.cpu().numpy().reshape((-1,)).astype(np.float64)\n",
    "\n",
    "  def ode_func(t, x):\n",
    "    \"\"\"The ODE function for use by the ODE solver.\"\"\"\n",
    "    time_steps = np.ones((shape[0],)) * t\n",
    "    g = diffusion_coeff(torch.tensor(t)).cpu().numpy()\n",
    "    return  -0.5 * (g**2) * score_eval_wrapper(x, time_steps)\n",
    "\n",
    "  # Run the black-box ODE solver.\n",
    "  res = integrate.solve_ivp(ode_func, (1., eps), initial_x.reshape(-1).cpu().numpy(), rtol=rtol, atol=atol, method='RK45')\n",
    "  print(f\"\\nNumber of function evaluations: {res.nfev}\")\n",
    "  x = [res.y[:, 0].reshape(shape)[0][None]]\n",
    "  T = len(res.t)\n",
    "  for i in range(N-1):\n",
    "    idx = int(i + (T/N))\n",
    "    x.append(res.y[:, idx].reshape(shape)[i][None])\n",
    "  x.append(res.y[:, -1].reshape(shape)[-1][None])\n",
    "  x = np.concatenate(x, axis = 0)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for sampling on a thread\n",
    "def diffuse_sample(channel, samples, diffusion_coeff, marginal_prob_std):\n",
    "\n",
    "  model_score = ScoreNet(marginal_prob_std=marginal_prob_std)\n",
    "  file = f'../model_cifar_thread_{channel}.pth'\n",
    "  ckpt = torch.load(file)\n",
    "  model_score.load_state_dict(ckpt)\n",
    "  model_score.eval();\n",
    "\n",
    "  sample_batch_size = N\n",
    "  sampler = ode_sampler\n",
    "\n",
    "  # Generate samples using the specified sampler.\n",
    "  output = sampler(model_score,\n",
    "                  marginal_prob_std,\n",
    "                  diffusion_coeff,\n",
    "                  sample_batch_size)\n",
    "\n",
    "  samples.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of function evaluations: 488\n",
      "\n",
      "Number of function evaluations: 488\n",
      "\n",
      "Number of function evaluations: 482\n"
     ]
    }
   ],
   "source": [
    "#@title Sample each channel on a thread\n",
    "threads = [None] * channels\n",
    "samples = []\n",
    "\n",
    "# diffuse all three channels concurrently\n",
    "for ch in range(channels):\n",
    "  threads[ch] = threading.Thread(target=diffuse_sample, args=[ch, samples, diffusion_coeff_fn, marginal_prob_std_fn])\n",
    "  threads[ch].start()\n",
    "\n",
    "for thread in threads:\n",
    "  thread.join()\n",
    "\n",
    "samples = np.concatenate(samples, axis = 1)\n",
    "for i in range(samples.shape[0]):\n",
    "  print(f'{samples[i].mean(), samples[i].std()}')\n",
    "  plt.imshow(((samples[i] - samples[i].min())/(samples[i].max() - samples[i].min())).transpose(1, 2, 0))\n",
    "  plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame(i):\n",
    "  return ((samples[i] - samples[i].min())/(samples[i].max() - samples[i].min())).transpose(1, 2, 0)\n",
    "\n",
    "fig = plt.figure(figsize=(8,8));\n",
    "\n",
    "im = plt.imshow(get_frame(0), animated=True)\n",
    "\n",
    "def frame(i):\n",
    "  im.set_data(get_frame(i));\n",
    "\n",
    "  return [im]\n",
    "\n",
    "animation_fig = animation.FuncAnimation(fig, frame, frames=samples.shape[-1], interval=10, blit=False,repeat_delay=2);\n",
    "\n",
    "animation_fig.save(\"animation.gif\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
