{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from tqdm import tqdm\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim import Adam\n",
    "\n",
    "from kfp_updated import construct_B, diffusion_coeff, construct_R, construct_P, gauss_seidel, solve_pde, logsumexp, construct_A\n",
    "from network import ScoreNet\n",
    "#from net_network import UNet\n",
    "\n",
    "import PIL\n",
    "\n",
    "np.random.seed(2)\n",
    "torch.manual_seed(2)\n",
    "\n",
    "\n",
    "# create a.so if doesnt exists\n",
    "if not os.path.isfile(\"../sparse_gaussian_elimination/a.so\"):\n",
    "    os.system(\"make -C ../sparse_gaussian_elimination a.so\")\n",
    "\n",
    "\n",
    "mnist = MNIST('.', download=True)\n",
    "\n",
    "channels = 1\n",
    "n_data = 1\n",
    "\n",
    "%load_ext line_profiler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcTUlEQVR4nO3df3DU9b3v8dcCyQqaLI0hv0rAgD+wAvEWJWZAxJJLSOc4gIwHf3QGvF4cMXiKaPXGUZHWM2nxjrV6qd7TqURnxB+cEaiO5Y4GE441oQNKGW7blNBY4iEJFSe7IUgIyef+wXXrQgJ+1l3eSXg+Zr4zZPf75vvx69Znv9nNNwHnnBMAAOfYMOsFAADOTwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYGGG9gFP19vbq4MGDSktLUyAQsF4OAMCTc04dHR3Ky8vTsGH9X+cMuAAdPHhQ+fn51ssAAHxDzc3NGjt2bL/PD7gApaWlSZJm6vsaoRTj1QAAfJ1Qtz7QO9H/nvcnaQFat26dnnrqKbW2tqqwsFDPPfecpk+ffta5L7/tNkIpGhEgQAAw6Pz/O4ye7W2UpHwI4fXXX9eqVau0evVqffTRRyosLFRpaakOHTqUjMMBAAahpATo6aef1rJly3TnnXfqO9/5jl544QWNGjVKL774YjIOBwAYhBIeoOPHj2vXrl0qKSn5x0GGDVNJSYnq6upO27+rq0uRSCRmAwAMfQkP0Geffaaenh5lZ2fHPJ6dna3W1tbT9q+srFQoFIpufAIOAM4P5j+IWlFRoXA4HN2am5utlwQAOAcS/im4zMxMDR8+XG1tbTGPt7W1KScn57T9g8GggsFgopcBABjgEn4FlJqaqmnTpqm6ujr6WG9vr6qrq1VcXJzowwEABqmk/BzQqlWrtGTJEl1zzTWaPn26nnnmGXV2durOO+9MxuEAAINQUgK0ePFi/f3vf9fjjz+u1tZWXX311dq6detpH0wAAJy/As45Z72Ir4pEIgqFQpqt+dwJAQAGoROuWzXaonA4rPT09H73M/8UHADg/ESAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYGGG9AGAgCYzw/5/E8DGZSVhJYjQ8eElccz2jer1nxk885D0z6t6A90zr06neMx9d87r3jCR91tPpPVO08QHvmUtX1XvPDAVcAQEATBAgAICJhAfoiSeeUCAQiNkmTZqU6MMAAAa5pLwHdNVVV+m99977x0Hi+L46AGBoS0oZRowYoZycnGT81QCAISIp7wHt27dPeXl5mjBhgu644w4dOHCg3327uroUiURiNgDA0JfwABUVFamqqkpbt27V888/r6amJl1//fXq6Ojoc//KykqFQqHolp+fn+glAQAGoIQHqKysTLfccoumTp2q0tJSvfPOO2pvb9cbb7zR5/4VFRUKh8PRrbm5OdFLAgAMQEn/dMDo0aN1+eWXq7Gxsc/ng8GggsFgspcBABhgkv5zQEeOHNH+/fuVm5ub7EMBAAaRhAfowQcfVG1trT755BN9+OGHWrhwoYYPH67bbrst0YcCAAxiCf8W3KeffqrbbrtNhw8f1pgxYzRz5kzV19drzJgxiT4UAGAQS3iAXnvttUT/lRighl95mfeMC6Z4zxy8YbT3zBfX+d9EUpIyQv5z/1EY340uh5rfHk3znvnZ/5rnPbNjygbvmabuL7xnJOmnbf/VeybvP1xcxzofcS84AIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMBE0n8hHQa+ntnfjWvu6ap13jOXp6TGdSycW92ux3vm8eeWes+M6PS/cWfxxhXeM2n/ecJ7RpKCn/nfxHTUzh1xHet8xBUQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATHA3bCjYcDCuuV3H8r1nLk9pi+tYQ80DLdd5z/z1SKb3TNXEf/eekaRwr/9dqrOf/TCuYw1k/mcBPrgCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDNS6ERLa1xzz/3sFu+Zf53X6T0zfM9F3jN/uPc575l4PfnZVO+ZxpJR3jM97S3eM7cX3+s9I0mf/Iv/TIH+ENexcP7iCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHNSBG3jPV13jNj3rrYe6bn8OfeM1dN/m/eM5L0f2e96D3zm3+7wXsmq/1D75l4BOriu0Fogf+/WsAbV0AAABMECABgwjtA27dv10033aS8vDwFAgFt3rw55nnnnB5//HHl5uZq5MiRKikp0b59+xK1XgDAEOEdoM7OThUWFmrdunV9Pr927Vo9++yzeuGFF7Rjxw5deOGFKi0t1bFjx77xYgEAQ4f3hxDKyspUVlbW53POOT3zzDN69NFHNX/+fEnSyy+/rOzsbG3evFm33nrrN1stAGDISOh7QE1NTWptbVVJSUn0sVAopKKiItXV9f2xmq6uLkUikZgNADD0JTRAra2tkqTs7OyYx7Ozs6PPnaqyslKhUCi65efnJ3JJAIAByvxTcBUVFQqHw9GtubnZekkAgHMgoQHKycmRJLW1tcU83tbWFn3uVMFgUOnp6TEbAGDoS2iACgoKlJOTo+rq6uhjkUhEO3bsUHFxcSIPBQAY5Lw/BXfkyBE1NjZGv25qatLu3buVkZGhcePGaeXKlXryySd12WWXqaCgQI899pjy8vK0YMGCRK4bADDIeQdo586duvHGG6Nfr1q1SpK0ZMkSVVVV6aGHHlJnZ6fuvvtutbe3a+bMmdq6dasuuOCCxK0aADDoBZxzznoRXxWJRBQKhTRb8zUikGK9HAxSf/nf18Y3908veM/c+bc53jN/n9nhPaPeHv8ZwMAJ160abVE4HD7j+/rmn4IDAJyfCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYML71zEAg8GVD/8lrrk7p/jf2Xr9+Oqz73SKG24p955Je73eewYYyLgCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDNSDEk97eG45g4vv9J75sBvvvCe+R9Pvuw9U/HPC71n3Mch7xlJyv/XOv8h5+I6Fs5fXAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GSnwFb1/+JP3zK1rfuQ988rq/+k9s/s6/xuY6jr/EUm66sIV3jOX/arFe+bEXz/xnsHQwRUQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGAi4Jxz1ov4qkgkolAopNmarxGBFOvlAEnhZlztPZP+00+9Z16d8H+8Z+I16f3/7j1zxZqw90zPvr96z+DcOuG6VaMtCofDSk9P73c/roAAACYIEADAhHeAtm/frptuukl5eXkKBALavHlzzPNLly5VIBCI2ebNm5eo9QIAhgjvAHV2dqqwsFDr1q3rd5958+appaUlur366qvfaJEAgKHH+zeilpWVqays7Iz7BINB5eTkxL0oAMDQl5T3gGpqapSVlaUrrrhCy5cv1+HDh/vdt6urS5FIJGYDAAx9CQ/QvHnz9PLLL6u6ulo/+9nPVFtbq7KyMvX09PS5f2VlpUKhUHTLz89P9JIAAAOQ97fgzubWW2+N/nnKlCmaOnWqJk6cqJqaGs2ZM+e0/SsqKrRq1aro15FIhAgBwHkg6R/DnjBhgjIzM9XY2Njn88FgUOnp6TEbAGDoS3qAPv30Ux0+fFi5ubnJPhQAYBDx/hbckSNHYq5mmpqatHv3bmVkZCgjI0Nr1qzRokWLlJOTo/379+uhhx7SpZdeqtLS0oQuHAAwuHkHaOfOnbrxxhujX3/5/s2SJUv0/PPPa8+ePXrppZfU3t6uvLw8zZ07Vz/5yU8UDAYTt2oAwKDHzUiBQWJ4dpb3zMHFl8Z1rB0P/8J7Zlgc39G/o2mu90x4Zv8/1oGBgZuRAgAGNAIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJhI+K/kBpAcPW2HvGeyn/WfkaRjD53wnhkVSPWe+dUlb3vP/NPCld4zozbt8J5B8nEFBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4GakgIHemVd7z+y/5QLvmclXf+I9I8V3Y9F4PPf5f/GeGbVlZxJWAgtcAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJrgZKfAVgWsme8/85V/8b9z5qxkvec/MuuC498y51OW6vWfqPy/wP1Bvi/8MBiSugAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE9yMFAPeiILx3jP778yL61hPLH7Ne2bRRZ/FdayB7JG2a7xnan9xnffMt16q857B0MEVEADABAECAJjwClBlZaWuvfZapaWlKSsrSwsWLFBDQ0PMPseOHVN5ebkuvvhiXXTRRVq0aJHa2toSumgAwODnFaDa2lqVl5ervr5e7777rrq7uzV37lx1dnZG97n//vv11ltvaePGjaqtrdXBgwd18803J3zhAIDBzetDCFu3bo35uqqqSllZWdq1a5dmzZqlcDisX//619qwYYO+973vSZLWr1+vK6+8UvX19bruOv83KQEAQ9M3eg8oHA5LkjIyMiRJu3btUnd3t0pKSqL7TJo0SePGjVNdXd+fdunq6lIkEonZAABDX9wB6u3t1cqVKzVjxgxNnjxZktTa2qrU1FSNHj06Zt/s7Gy1trb2+fdUVlYqFApFt/z8/HiXBAAYROIOUHl5ufbu3avXXvP/uYmvqqioUDgcjm7Nzc3f6O8DAAwOcf0g6ooVK/T2229r+/btGjt2bPTxnJwcHT9+XO3t7TFXQW1tbcrJyenz7woGgwoGg/EsAwAwiHldATnntGLFCm3atEnbtm1TQUFBzPPTpk1TSkqKqquro481NDTowIEDKi4uTsyKAQBDgtcVUHl5uTZs2KAtW7YoLS0t+r5OKBTSyJEjFQqFdNddd2nVqlXKyMhQenq67rvvPhUXF/MJOABADK8APf/885Kk2bNnxzy+fv16LV26VJL085//XMOGDdOiRYvU1dWl0tJS/fKXv0zIYgEAQ0fAOeesF/FVkUhEoVBIszVfIwIp1svBGYy4ZJz3THharvfM4h9vPftOp7hn9F+9Zwa6B1r8v4tQ90v/m4pKUkbV7/2HenviOhaGnhOuWzXaonA4rPT09H73415wAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMBHXb0TFwDUit+/fPHsmn794YVzHWl5Q6z1zW1pbXMcayFb850zvmY+ev9p7JvPf93rPZHTUec8A5wpXQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACW5Geo4cL73Gf+b+z71nHrn0He+ZuSM7vWcGuraeL+Kam/WbB7xnJj36Z++ZjHb/m4T2ek8AAxtXQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACW5Geo58ssC/9X+ZsjEJK0mcde0TvWd+UTvXeybQE/CemfRkk/eMJF3WtsN7pieuIwHgCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMBFwzjnrRXxVJBJRKBTSbM3XiECK9XIAAJ5OuG7VaIvC4bDS09P73Y8rIACACQIEADDhFaDKykpde+21SktLU1ZWlhYsWKCGhoaYfWbPnq1AIBCz3XPPPQldNABg8PMKUG1trcrLy1VfX693331X3d3dmjt3rjo7O2P2W7ZsmVpaWqLb2rVrE7poAMDg5/UbUbdu3RrzdVVVlbKysrRr1y7NmjUr+vioUaOUk5OTmBUCAIakb/QeUDgcliRlZGTEPP7KK68oMzNTkydPVkVFhY4ePdrv39HV1aVIJBKzAQCGPq8roK/q7e3VypUrNWPGDE2ePDn6+O23367x48crLy9Pe/bs0cMPP6yGhga9+eabff49lZWVWrNmTbzLAAAMUnH/HNDy5cv129/+Vh988IHGjh3b737btm3TnDlz1NjYqIkTJ572fFdXl7q6uqJfRyIR5efn83NAADBIfd2fA4rrCmjFihV6++23tX379jPGR5KKiookqd8ABYNBBYPBeJYBABjEvALknNN9992nTZs2qaamRgUFBWed2b17tyQpNzc3rgUCAIYmrwCVl5drw4YN2rJli9LS0tTa2ipJCoVCGjlypPbv368NGzbo+9//vi6++GLt2bNH999/v2bNmqWpU6cm5R8AADA4eb0HFAgE+nx8/fr1Wrp0qZqbm/WDH/xAe/fuVWdnp/Lz87Vw4UI9+uijZ/w+4FdxLzgAGNyS8h7Q2VqVn5+v2tpan78SAHCe4l5wAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATI6wXcCrnnCTphLolZ7wYAIC3E+qW9I//nvdnwAWoo6NDkvSB3jFeCQDgm+jo6FAoFOr3+YA7W6LOsd7eXh08eFBpaWkKBAIxz0UiEeXn56u5uVnp6elGK7THeTiJ83AS5+EkzsNJA+E8OOfU0dGhvLw8DRvW/zs9A+4KaNiwYRo7duwZ90lPTz+vX2Bf4jycxHk4ifNwEufhJOvzcKYrny/xIQQAgAkCBAAwMagCFAwGtXr1agWDQeulmOI8nMR5OInzcBLn4aTBdB4G3IcQAADnh0F1BQQAGDoIEADABAECAJggQAAAE4MmQOvWrdMll1yiCy64QEVFRfr9739vvaRz7oknnlAgEIjZJk2aZL2spNu+fbtuuukm5eXlKRAIaPPmzTHPO+f0+OOPKzc3VyNHjlRJSYn27dtns9gkOtt5WLp06Wmvj3nz5tksNkkqKyt17bXXKi0tTVlZWVqwYIEaGhpi9jl27JjKy8t18cUX66KLLtKiRYvU1tZmtOLk+DrnYfbs2ae9Hu655x6jFfdtUATo9ddf16pVq7R69Wp99NFHKiwsVGlpqQ4dOmS9tHPuqquuUktLS3T74IMPrJeUdJ2dnSosLNS6dev6fH7t2rV69tln9cILL2jHjh268MILVVpaqmPHjp3jlSbX2c6DJM2bNy/m9fHqq6+ewxUmX21trcrLy1VfX693331X3d3dmjt3rjo7O6P73H///Xrrrbe0ceNG1dbW6uDBg7r55psNV514X+c8SNKyZctiXg9r1641WnE/3CAwffp0V15eHv26p6fH5eXlucrKSsNVnXurV692hYWF1sswJclt2rQp+nVvb6/LyclxTz31VPSx9vZ2FwwG3auvvmqwwnPj1PPgnHNLlixx8+fPN1mPlUOHDjlJrra21jl38t99SkqK27hxY3SfP/3pT06Sq6urs1pm0p16Hpxz7oYbbnA//OEP7Rb1NQz4K6Djx49r165dKikpiT42bNgwlZSUqK6uznBlNvbt26e8vDxNmDBBd9xxhw4cOGC9JFNNTU1qbW2NeX2EQiEVFRWdl6+PmpoaZWVl6YorrtDy5ct1+PBh6yUlVTgcliRlZGRIknbt2qXu7u6Y18OkSZM0bty4If16OPU8fOmVV15RZmamJk+erIqKCh09etRief0acDcjPdVnn32mnp4eZWdnxzyenZ2tP//5z0arslFUVKSqqipdccUVamlp0Zo1a3T99ddr7969SktLs16eidbWVknq8/Xx5XPni3nz5unmm29WQUGB9u/fr0ceeURlZWWqq6vT8OHDrZeXcL29vVq5cqVmzJihyZMnSzr5ekhNTdXo0aNj9h3Kr4e+zoMk3X777Ro/frzy8vK0Z88ePfzww2poaNCbb75puNpYAz5A+IeysrLon6dOnaqioiKNHz9eb7zxhu666y7DlWEguPXWW6N/njJliqZOnaqJEyeqpqZGc+bMMVxZcpSXl2vv3r3nxfugZ9Lfebj77rujf54yZYpyc3M1Z84c7d+/XxMnTjzXy+zTgP8WXGZmpoYPH37ap1ja2tqUk5NjtKqBYfTo0br88svV2NhovRQzX74GeH2cbsKECcrMzBySr48VK1bo7bff1vvvvx/z61tycnJ0/Phxtbe3x+w/VF8P/Z2HvhQVFUnSgHo9DPgApaamatq0aaquro4+1tvbq+rqahUXFxuuzN6RI0e0f/9+5ebmWi/FTEFBgXJycmJeH5FIRDt27DjvXx+ffvqpDh8+PKReH845rVixQps2bdK2bdtUUFAQ8/y0adOUkpIS83poaGjQgQMHhtTr4WznoS+7d++WpIH1erD+FMTX8dprr7lgMOiqqqrcH//4R3f33Xe70aNHu9bWVuulnVMPPPCAq6mpcU1NTe53v/udKykpcZmZme7QoUPWS0uqjo4O9/HHH7uPP/7YSXJPP/20+/jjj93f/vY355xzP/3pT93o0aPdli1b3J49e9z8+fNdQUGB++KLL4xXnlhnOg8dHR3uwQcfdHV1da6pqcm999577rvf/a677LLL3LFjx6yXnjDLly93oVDI1dTUuJaWluh29OjR6D733HOPGzdunNu2bZvbuXOnKy4udsXFxYarTryznYfGxkb34x//2O3cudM1NTW5LVu2uAkTJrhZs2YZrzzWoAiQc84999xzbty4cS41NdVNnz7d1dfXWy/pnFu8eLHLzc11qamp7tvf/rZbvHixa2xstF5W0r3//vtO0mnbkiVLnHMnP4r92GOPuezsbBcMBt2cOXNcQ0OD7aKT4Ezn4ejRo27u3LluzJgxLiUlxY0fP94tW7ZsyP2ftL7++SW59evXR/f54osv3L333uu+9a1vuVGjRrmFCxe6lpYWu0UnwdnOw4EDB9ysWbNcRkaGCwaD7tJLL3U/+tGPXDgctl34Kfh1DAAAEwP+PSAAwNBEgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJj4f4W4/AnknuSPAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.data[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## construct the grid and Initial values\n",
    "batch_size = 32\n",
    "N = 10\n",
    "H = 28\n",
    "W = 28\n",
    "epoch = 5\n",
    "eps = 1e-6\n",
    "\n",
    "channels = 3\n",
    "\n",
    "t = np.linspace(eps, 1, N)\n",
    "dt = 1/N\n",
    "\n",
    "sigma = 25\n",
    "\n",
    "# create model\n",
    "model_score = ScoreNet(H=H, W=W, in_channels=channels)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = Adam(model_score.parameters(), lr=1e-3)\n",
    "mm_scaler = MinMaxScaler()\n",
    "model_score.train();\n",
    "\n",
    "#scores = np.random.rand(N, channels, H, W).astype(np.float64)\n",
    "scores = np.zeros((N,channels, H, W), dtype=np.float32)\n",
    "\n",
    "params = {\"bandwidth\": np.logspace(-1, 1, 20)}\n",
    "kdes = np.full((n_data, channels), None)\n",
    "\n",
    "P = construct_P(int(W), int(H/2))\n",
    "P_block = sp.linalg.block_diag(*([P] * (N-1)))\n",
    "sparse_P_block = sp.sparse.block_diag(([P] * (N-1)))\n",
    "\n",
    "R = construct_R(P)\n",
    "R_block = sp.linalg.block_diag(*([R] * (N-1)))\n",
    "sparse_R_block = sp.sparse.block_diag(([R] * (N-1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffuse(data, x, m , del_m, m_c, channel, train_xc_data, train_x_data, train_y_data, random_t, time_, sigma_, data_idx):\n",
    "    data = data[channel]\n",
    "    dx = data.detach().numpy().max()/H\n",
    "    dy = data.detach().numpy().max()/W\n",
    "    x[channel][0] = torch.tensor(mm_scaler.fit_transform(data.ravel()[:, None]).astype(np.float32)).reshape((1, 1, H, W))\n",
    "    \n",
    "    if not kdes[data_idx, channel]:\n",
    "      grid = GridSearchCV(KernelDensity(), params)\n",
    "      kdes[data_idx, channel] = grid.fit(data.ravel()[:, None]) # 0.7 sec\n",
    "    \n",
    "    m[channel][0] = kdes[data_idx, channel].score_samples(data.ravel()[:, None])\n",
    "    del_m[channel][0] = np.diff(m[channel][0].ravel(), axis=0, prepend=m[channel][0,0])\n",
    "    \n",
    "    # we normalize for sigma to ensure the dynamics doesn't blow up\n",
    "    As = []\n",
    "    for i, t_ in enumerate(random_t, 1):\n",
    "      A = construct_A(dx, dy, t_ - time_[i-1], np.sqrt(2) * sigma_[i], scores[i][channel].ravel(), H, W)\n",
    "      As.append(A)\n",
    "\n",
    "    A_block = sp.linalg.block_diag(*As)\n",
    "    for i, t_ in enumerate(random_t, 1):\n",
    "      if i == 1:\n",
    "        continue\n",
    "      A_block[(i-1)*H*W:i*H*W, (i-2)*H*W:(i-1)*H*W] = -np.eye((H*W))/(t_ - time_[i-1])\n",
    "    \n",
    "    \n",
    "    B = construct_B(dx, dy, time_[1] - time_[0], m[channel][0].ravel(), np.zeros((H*W)), sigma_[1], scores[i][channel].ravel())\n",
    "    B_block = np.zeros(A_block.shape[0])\n",
    "    B_block[:H*W] = B\n",
    "    \n",
    "    # update m (pre-smoothing)\n",
    "    \n",
    "    m[channel][1:] = gauss_seidel(A_block, B_block, scores[1:, channel].flatten(), A_block.shape[0]).reshape(((N-1), H*W)) # 0.4\n",
    "    \n",
    "    \n",
    "    ##### 0.5\n",
    "    # we want to perform the coarse grid\n",
    "    # compute residual r = b - Am[1:]\n",
    "    r = B_block - A_block@(m[channel][1:]).flatten()\n",
    "    # coursening step 1: r_c = R_c@r\n",
    "    r_c = R_block@r\n",
    "    # coursening A_c = R_c@A@P_c (Petrov-Galerkin Coursening)\n",
    "\n",
    "    sparse_A_block = sparse.csr_matrix(A_block)\n",
    "    \n",
    "    A_c = (sparse_R_block@sparse_A_block@sparse_P_block) # 0.5\n",
    "    \n",
    "    # compute course err: err_c = solve_pde(A_c,r_c)\n",
    "    err_c = solve_pde(A_c, r_c, mode='sp_sparse')\n",
    "    \n",
    "    # interpolate to fine grid: err = P_c@err_c\n",
    "    #print(P_block.shape)\n",
    "    #print(err_c)\n",
    "    err = P_block@err_c\n",
    "    # we apply fine grid-correction\n",
    "    m[channel][1:] = (m[channel][1:].flatten() + err).reshape((N-1, H*W))\n",
    "    # post smoothing\n",
    "    m[channel][1:] = gauss_seidel(A_block, B_block, m[channel][1:].flatten(), A_block.shape[0]).reshape(((N-1), H*W))\n",
    "\n",
    "    # we want to coarsen the score function to train on coarse data\n",
    "    m_c[channel][1:] = (R_block@m[channel][1:].flatten()).reshape((-1, int(H*W/4)))\n",
    "\n",
    "    # constructing the training data and labels\n",
    "    for i, t_ in enumerate(random_t, 1):\n",
    "      del_m[channel][i] = np.diff(m[channel][i].ravel(), axis=0, prepend=m[channel][i, 0])\n",
    "\n",
    "    x = torch.tensor(mm_scaler.fit_transform(np.exp((-m[channel].ravel() - logsumexp(-m[channel].ravel())))[:, None])).reshape((N, 1, H, W))\n",
    "    perturbed_x = x + torch.randn_like(x) * torch.sqrt(2 * torch.tensor(sigma_)**2)[:, None, None, None]\n",
    "    train_x_data[:, channel] = perturbed_x[:, 0]\n",
    "    train_y_data[:, channel] = torch.tensor(del_m[channel].astype(np.float32)).reshape((N, H, W))\n",
    "\n",
    "    # generate coarse dataset\n",
    "    x_c = torch.tensor(mm_scaler.fit_transform(np.exp((-m_c[channel].ravel() - logsumexp(-m_c[channel].ravel())))[:, None])).reshape((N, int(H/2), int(W/2)))\n",
    "    perturbed_xc = x_c + torch.randn_like(x_c) * torch.sqrt(2 * torch.tensor(sigma_)**2)[:, None, None]\n",
    "    train_xc_data[:, channel] = perturbed_xc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 0.1 s\n",
      "\n",
      "Total time: 1.38967 s\n",
      "File: /tmp/ipykernel_2472575/3416826710.py\n",
      "Function: diffuse at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           def diffuse(data, x, m , del_m, m_c, channel, train_xc_data, train_x_data, train_y_data, random_t, time_, sigma_, data_idx):\n",
      "     2         1          0.0      0.0      0.0      data = data[channel]\n",
      "     3         1          0.0      0.0      0.0      dx = data.detach().numpy().max()/H\n",
      "     4         1          0.0      0.0      0.0      dy = data.detach().numpy().max()/W\n",
      "     5         1          0.0      0.0      0.1      x[channel][0] = torch.tensor(mm_scaler.fit_transform(data.ravel()[:, None]).astype(np.float32)).reshape((1, 1, H, W))\n",
      "     6                                               \n",
      "     7         1          0.0      0.0      0.0      if not kdes[data_idx, channel]:\n",
      "     8                                                 grid = GridSearchCV(KernelDensity(), params)\n",
      "     9                                                 kdes[data_idx, channel] = grid.fit(data.ravel()[:, None]) # 0.7 sec\n",
      "    10                                               \n",
      "    11         1          0.6      0.6      4.4      m[channel][0] = kdes[data_idx, channel].score_samples(data.ravel()[:, None])\n",
      "    12         1          0.0      0.0      0.0      del_m[channel][0] = np.diff(m[channel][0].ravel(), axis=0, prepend=m[channel][0,0])\n",
      "    13                                               \n",
      "    14                                               # we normalize for sigma to ensure the dynamics doesn't blow up\n",
      "    15         1          0.0      0.0      0.0      As = []\n",
      "    16        10          0.0      0.0      0.0      for i, t_ in enumerate(random_t, 1):\n",
      "    17         9          1.2      0.1      8.8        A = construct_A(dx, dy, t_ - time_[i-1], np.sqrt(2) * sigma_[i], scores[i][channel].ravel(), H, W)\n",
      "    18         9          0.0      0.0      0.0        As.append(A)\n",
      "    19                                           \n",
      "    20         1          0.3      0.3      2.5      A_block = sp.linalg.block_diag(*As)\n",
      "    21        10          0.0      0.0      0.0      for i, t_ in enumerate(random_t, 1):\n",
      "    22         9          0.0      0.0      0.0        if i == 1:\n",
      "    23         1          0.0      0.0      0.0          continue\n",
      "    24         8          0.3      0.0      1.9        A_block[(i-1)*H*W:i*H*W, (i-2)*H*W:(i-1)*H*W] = -np.eye((H*W))/(t_ - time_[i-1])\n",
      "    25                                               \n",
      "    26                                               \n",
      "    27         1          0.0      0.0      0.0      B = construct_B(dx, dy, time_[1] - time_[0], m[channel][0].ravel(), np.zeros((H*W)), sigma_[1], scores[i][channel].ravel())\n",
      "    28         1          0.0      0.0      0.0      B_block = np.zeros(A_block.shape[0])\n",
      "    29         1          0.0      0.0      0.0      B_block[:H*W] = B\n",
      "    30                                               \n",
      "    31                                               # update m (pre-smoothing)\n",
      "    32                                               \n",
      "    33         1          3.7      3.7     26.4      m[channel][1:] = gauss_seidel(A_block, B_block, scores[1:, channel].flatten(), A_block.shape[0]).reshape(((N-1), H*W)) # 0.4\n",
      "    34                                               \n",
      "    35                                               \n",
      "    36                                               ##### 0.5\n",
      "    37                                               # we want to perform the coarse grid\n",
      "    38                                               # compute residual r = b - Am[1:]\n",
      "    39         1          0.1      0.1      0.4      r = B_block - A_block@(m[channel][1:]).flatten()\n",
      "    40                                               # coursening step 1: r_c = R_c@r\n",
      "    41         1          0.0      0.0      0.1      r_c = R_block@r\n",
      "    42                                               # coursening A_c = R_c@A@P_c (Petrov-Galerkin Coursening)\n",
      "    43                                           \n",
      "    44         1          2.8      2.8     20.2      sparse_A_block = sparse.csr_matrix(A_block)\n",
      "    45                                               \n",
      "    46         1          1.3      1.3      9.2      A_c = (sparse_R_block@sparse_A_block@sparse_P_block) # 0.5\n",
      "    47                                               \n",
      "    48                                               # compute course err: err_c = solve_pde(A_c,r_c)\n",
      "    49         1          0.3      0.3      2.2      err_c = solve_pde(A_c, r_c, mode='sp_sparse')\n",
      "    50                                               \n",
      "    51                                               # interpolate to fine grid: err = P_c@err_c\n",
      "    52                                               #print(P_block.shape)\n",
      "    53                                               #print(err_c)\n",
      "    54         1          0.0      0.0      0.1      err = P_block@err_c\n",
      "    55                                               # we apply fine grid-correction\n",
      "    56         1          0.0      0.0      0.0      m[channel][1:] = (m[channel][1:].flatten() + err).reshape((N-1, H*W))\n",
      "    57                                               # post smoothing\n",
      "    58         1          3.3      3.3     23.5      m[channel][1:] = gauss_seidel(A_block, B_block, m[channel][1:].flatten(), A_block.shape[0]).reshape(((N-1), H*W))\n",
      "    59                                           \n",
      "    60                                               # we want to coarsen the score function to train on coarse data\n",
      "    61         1          0.0      0.0      0.1      m_c[channel][1:] = (R_block@m[channel][1:].flatten()).reshape((-1, int(H*W/4)))\n",
      "    62                                           \n",
      "    63                                               # constructing the training data and labels\n",
      "    64        10          0.0      0.0      0.0      for i, t_ in enumerate(random_t, 1):\n",
      "    65         9          0.0      0.0      0.0        del_m[channel][i] = np.diff(m[channel][i].ravel(), axis=0, prepend=m[channel][i, 0])\n",
      "    66                                           \n",
      "    67         1          0.0      0.0      0.1      x = torch.tensor(mm_scaler.fit_transform(np.exp((-m[channel].ravel() - logsumexp(-m[channel].ravel())))[:, None])).reshape((N, 1, H, W))\n",
      "    68         1          0.0      0.0      0.0      perturbed_x = x + torch.randn_like(x) * torch.sqrt(2 * torch.tensor(sigma_)**2)[:, None, None, None]\n",
      "    69         1          0.0      0.0      0.0      train_x_data[:, channel] = perturbed_x[:, 0]\n",
      "    70         1          0.0      0.0      0.0      train_y_data[:, channel] = torch.tensor(del_m[channel].astype(np.float32)).reshape((N, H, W))\n",
      "    71                                           \n",
      "    72                                               # generate coarse dataset\n",
      "    73         1          0.0      0.0      0.0      x_c = torch.tensor(mm_scaler.fit_transform(np.exp((-m_c[channel].ravel() - logsumexp(-m_c[channel].ravel())))[:, None])).reshape((N, int(H/2), int(W/2)))\n",
      "    74         1          0.0      0.0      0.0      perturbed_xc = x_c + torch.randn_like(x_c) * torch.sqrt(2 * torch.tensor(sigma_)**2)[:, None, None]\n",
      "    75         1          0.0      0.0      0.0      train_xc_data[:, channel] = perturbed_xc"
     ]
    }
   ],
   "source": [
    "\n",
    "x = torch.zeros((channels, N, H, W))\n",
    "m = np.zeros((channels, N, H*W), dtype=np.float32)\n",
    "del_m = np.zeros_like(m, dtype=np.float32)\n",
    "m_c = np.zeros((channels, N, int((H*W/4))), dtype=np.float32)\n",
    "# we want to sample from random time steps to construct training samples\n",
    "random_t = np.linspace([dt + eps] * n_data, [1] * n_data, N-1, axis=1).astype(np.float64)\n",
    "random_t += np.random.uniform(-dt/2, dt/2, random_t.shape)\n",
    "random_t[:, -1] = 1\n",
    "time_ = np.sort(np.insert(random_t, 0, eps, axis=1), axis=1).astype(np.float32)\n",
    "sigma_ = diffusion_coeff(torch.tensor(time_), sigma).detach().cpu().numpy()\n",
    "\n",
    "data = mnist.data[0].reshape(1, 28, 28)\n",
    "train_xc_data = torch.zeros((N, channels, int(H/2), int(W/2)))\n",
    "train_x_data = torch.zeros((N, channels, H, W))\n",
    "train_y_data = torch.zeros_like(train_x_data)\n",
    "\n",
    "#%lprun -u 0.1 -f construct_A_test construct_A_test(0.01, 0.01, random_t[0] - time_[0][:N-1],  np.zeros((N-1, H, W)), sigma_[0][1:], scores[1:, 0], H, W)\n",
    "%lprun -u 0.1 -f diffuse diffuse(data, x, m, del_m, m_c, 0, train_xc_data, train_x_data, train_y_data, random_t[0], time_[0], sigma_[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 2, 3], [3, 4, 5]])\n",
    "b = np.array([1, 2, 3])\n",
    "(a + b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
