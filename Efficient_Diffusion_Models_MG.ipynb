{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrew-na-git/Stable-Diffusion/blob/main/Efficient_Diffusion_Models_MG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So7QOL_4HuCP"
      },
      "source": [
        "# Diffusion models Testing\n",
        "\n",
        "In this document we test and build diffusion models and its variations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd-FQFjbkCy2"
      },
      "source": [
        "# Solving the KFP equation\n",
        "\n",
        "We present classical methods to solve the KFP forward equation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZm8EkvVTmqW"
      },
      "source": [
        "# Compile Sparse Solver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vg7cp68CTmqW",
        "outputId": "61074aef-c33e-4e28-85b5-d86de496aba6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "make: Entering directory '/content/sparse_gaussian_elimination'\n",
            "gcc  -c -g -fPIC main.c\n",
            "gcc  -c -g -fPIC solver.c\n",
            "gcc  -c -g -fPIC rcm.c\n",
            "gcc  -c -g -fPIC colamd.c\n",
            "gcc  -c -g -fPIC mindeg.c\n",
            "gcc -shared main.o solver.o colamd.o\\\n",
            "                        mindeg.o rcm.o -o a.so\n",
            "make: Leaving directory '/content/sparse_gaussian_elimination'\n"
          ]
        }
      ],
      "source": [
        "!make -C sparse_gaussian_elimination a.so"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QERPscoSrIzG"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FxS8Q5zHd-z"
      },
      "outputs": [],
      "source": [
        "## We start with standard diffusion model denoising diffusion probability model\n",
        "## we first start by loading the required packages\n",
        "import torch\n",
        "import functools\n",
        "from torch.optim import Adam, SGD\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import scipy as sp\n",
        "from scipy.sparse import coo_array\n",
        "import numpy as np\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KernelDensity\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sparse_solver import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D45yl1drKub"
      },
      "source": [
        "## Loading MNIST Digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgysHg20JZ5H",
        "outputId": "9a084073-8d81-41ec-b99b-dfec6f8509cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 96846258.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 80595937.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 1648877/1648877 [00:00<00:00, 22086961.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 14767851.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "(60000, 28, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# download mnist dataset\n",
        "mnist = MNIST('.', train=True, transform=transforms.ToTensor(), download=True)\n",
        "# mnist_data = np.moveaxis(mnist.data.numpy(), 0, -1)\n",
        "# mnist_data.shape\n",
        "mnist_data = mnist.data.numpy()\n",
        "print(mnist_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "wHBxXAabLgsS",
        "outputId": "bedc0f07-8edf-4bd2-b985-3478760a7ca8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7d2ff1fc35b0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# look at one of the images\n",
        "\n",
        "plt.imshow(mnist_data[0,:,:], cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlN4251JrOnc"
      },
      "source": [
        "## Solving the KFP Equation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2lr4BZ95NBI"
      },
      "outputs": [],
      "source": [
        "## we construct coefficient matrix and constant matrix\n",
        "def construct_A(dx,dy,dt,f,g,s,H,W):\n",
        "  A = np.eye(H*W)/dt + np.diag((f - 0.5*((g**2)*s)).ravel())/dx + np.diag((f - 0.5*((g**2)*s)).ravel())/dy \\\n",
        "                  + np.diag((-f + 0.5*((g**2)*s)).ravel()[1:],1)/dx + np.diag((-f + 0.5*((g**2)*s)).ravel()[1:],-1)/dy\n",
        "  return A\n",
        "\n",
        "def construct_B(dx,dy,dt,m_prev,f,g,s):\n",
        "  B = m_prev - (np.diff(f, axis=0, prepend=f[0,0]).ravel()*dt/dx + np.diff(f, axis=-1, prepend=f[0,0]).ravel()*dt/dy \\\n",
        "               - 0.5*(g**2)*(np.diff(s, axis=0, prepend = s[0,0]).ravel()*dt/dx + np.diff(s, axis=-1, prepend = s[0,0]).ravel()*dt/dy))\n",
        "  return B/dt\n",
        "\n",
        "def construct_R(N,M):\n",
        "  R = np.zeros((N, M))\n",
        "  for i in range(N):\n",
        "    for j in range(M-3):\n",
        "      if i  == 0 and j == 0:\n",
        "        R[i,j] = 1/2\n",
        "        R[i,j+1] = 1\n",
        "        R[i,j+2] = 1/2\n",
        "      elif i > 0 and j == 2 * i:\n",
        "        R[i,j] = 1/2\n",
        "        R[i,j+1] = 1\n",
        "        R[i,j+2] = 1/2\n",
        "      elif i == N-1 and j == M-4:\n",
        "        R[i,-2] = 1/2\n",
        "        R[i,-1] = 1/2\n",
        "  R = 0.5*R\n",
        "  R = np.kron(R,R)\n",
        "  return R\n",
        "\n",
        "def construct_P(R):\n",
        "  return R.transpose()\n",
        "\n",
        "def solve_pde(A,b,mode='dense'):\n",
        "  if mode == 'dense':\n",
        "    return sp.linalg.solve(A, b)\n",
        "  if mode == 'sparse':\n",
        "    return sparse_solve(A, b)\n",
        "\n",
        "def construct_R_block(R, R_block, i):\n",
        "  if i == 1:\n",
        "    R_block = sp.linalg.block_diag(R)\n",
        "  else:\n",
        "    R_block = sp.linalg.block_diag(R_block, R)\n",
        "  return R_block\n",
        "\n",
        "def construct_P_block(P, P_block, i):\n",
        "  if i == 1:\n",
        "    P_block = sp.linalg.block_diag(P)\n",
        "  else:\n",
        "    P_block = sp.linalg.block_diag(P_block, P)\n",
        "  return P_block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "camwRJtmNCii"
      },
      "outputs": [],
      "source": [
        "def marginal_prob_std(t, sigma):\n",
        "  \"\"\"Compute the mean and standard deviation of $p_{0t}(x(t) | x(0))$.\n",
        "\n",
        "  Args:\n",
        "    t: A vector of time steps.\n",
        "    sigma: The $\\sigma$ in our SDE.\n",
        "\n",
        "  Returns:\n",
        "    The standard deviation.\n",
        "  \"\"\"\n",
        "  return torch.sqrt((sigma**(2 * t) - 1.) / 2. / np.log(sigma))\n",
        "\n",
        "def diffusion_coeff(t, sigma):\n",
        "  \"\"\"Compute the diffusion coefficient of our SDE.\n",
        "\n",
        "  Args:\n",
        "    t: A vector of time steps.\n",
        "    sigma: The $\\sigma$ in our SDE.\n",
        "\n",
        "  Returns:\n",
        "    The vector of diffusion coefficients.\n",
        "  \"\"\"\n",
        "  return sigma**t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcoxsqqffAHR"
      },
      "outputs": [],
      "source": [
        "def gauss_seidel(A, b, x):\n",
        "    #x is the initial condition\n",
        "    x_old  = x.copy()\n",
        "\n",
        "    #Loop over rows\n",
        "    for i in range(A.shape[0]):\n",
        "        x[i] = (b[i] - np.dot(A[i,:i], x[:i]) - np.dot(A[i,(i+1):], x_old[(i+1):])) / A[i ,i]\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iv4QhuvJNmm"
      },
      "source": [
        "## Initialize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzIWwurbaRvi"
      },
      "outputs": [],
      "source": [
        "## construct the grid and Initial values\n",
        "batch_size = 32\n",
        "N_img = mnist.data.shape[0] //batch_size # for denoising, just use a constant\n",
        "N = 10\n",
        "H = mnist.data.shape[1]\n",
        "W = mnist.data.shape[2]\n",
        "epoch = 20\n",
        "eps = 1e-6\n",
        "\n",
        "dataset = mnist\n",
        "dx = mnist.data[0].detach().numpy().max()/H\n",
        "dy = mnist.data[0].detach().numpy().max()/W\n",
        "data_loader = DataLoader(dataset, batch_size=N, shuffle=True, num_workers=1)\n",
        "\n",
        "t = np.linspace(eps, 1, N)\n",
        "dt = 1/N\n",
        "\n",
        "# f = np.zeros((N, H, W))\n",
        "# g = np.zeros_like(f)\n",
        "x = torch.zeros((N, 1, H, W))\n",
        "m = np.zeros((N, H*W), dtype=np.float32)\n",
        "del_m = np.zeros_like(m, dtype=np.float32)\n",
        "\n",
        "m_c = np.zeros((N, int((H*W/4))), dtype=np.float32)\n",
        "del_m_c = np.zeros_like(m_c, dtype=np.float32)\n",
        "\n",
        "perturbed_x = torch.zeros_like(x)\n",
        "scores = np.zeros((N, H, W), dtype=np.float32)\n",
        "sigma_ = np.ones(N, dtype=np.float32)\n",
        "\n",
        "sigma = 2 # in our application sigma needs to be small"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IchHH39yXca"
      },
      "source": [
        "## Define the network model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXVvIj2A0H9y"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import functools\n",
        "\n",
        "class GaussianFourierProjection(nn.Module):\n",
        "  \"\"\"Gaussian random features for encoding time steps.\"\"\"\n",
        "  def __init__(self, embed_dim, scale=30.):\n",
        "    super().__init__()\n",
        "    # Randomly sample weights during initialization. These weights are fixed\n",
        "    # during optimization and are not trainable.\n",
        "    self.W = nn.Parameter(torch.randn(embed_dim // 2) * scale, requires_grad=False)\n",
        "  def forward(self, x):\n",
        "    x_proj = x[:, None] * self.W[None, :] * 2 * np.pi\n",
        "    return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
        "\n",
        "\n",
        "class Dense(nn.Module):\n",
        "  \"\"\"A fully connected layer that reshapes outputs to feature maps.\"\"\"\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super().__init__()\n",
        "    self.dense = nn.Linear(input_dim, output_dim)\n",
        "  def forward(self, x):\n",
        "    return self.dense(x)[..., None, None]\n",
        "\n",
        "class Coarse(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.coarse = nn.Linear(int(H*W/4), H*W)\n",
        "  def forward(self, x, coarse=False):\n",
        "    return self.coarse(x).reshape((-1, 1, int(H), int(W)))\n",
        "\n",
        "class ScoreNet(nn.Module):\n",
        "  \"\"\"A time-dependent score-based model built upon U-Net architecture.\"\"\"\n",
        "\n",
        "  def __init__(self, channels=[32, 64, 128, 256], embed_dim=256):\n",
        "    \"\"\"Initialize a time-dependent score-based network.\n",
        "\n",
        "    Args:\n",
        "      channels: The number of channels for feature maps of each resolution.\n",
        "      embed_dim: The dimensionality of Gaussian random feature embeddings.\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    # Gaussian random feature embedding layer for time\n",
        "    self.embed = nn.Sequential(GaussianFourierProjection(embed_dim=embed_dim),\n",
        "         nn.Linear(embed_dim, embed_dim))\n",
        "    # for Coarse matrices we want to upscale\n",
        "    self.coarse = Coarse()\n",
        "    # Encoding layers where the resolution decreases\n",
        "    self.conv1 = nn.Conv2d(1, channels[0], 3, stride=1, bias=True)\n",
        "    self.dense1 = Dense(embed_dim, channels[0])\n",
        "    self.gnorm1 = nn.GroupNorm(4, num_channels=channels[0])\n",
        "    self.conv2 = nn.Conv2d(channels[0], channels[1], 3, stride=2, bias=False)\n",
        "    self.dense2 = Dense(embed_dim, channels[1])\n",
        "    self.gnorm2 = nn.GroupNorm(32, num_channels=channels[1])\n",
        "    self.conv3 = nn.Conv2d(channels[1], channels[2], 3, stride=2, bias=False)\n",
        "    self.dense3 = Dense(embed_dim, channels[2])\n",
        "    self.gnorm3 = nn.GroupNorm(32, num_channels=channels[2])\n",
        "    self.conv4 = nn.Conv2d(channels[2], channels[3], 3, stride=2, bias=False)\n",
        "    self.dense4 = Dense(embed_dim, channels[3])\n",
        "    self.gnorm4 = nn.GroupNorm(32, num_channels=channels[3])\n",
        "\n",
        "    # Decoding layers where the resolution increases\n",
        "    self.tconv4 = nn.ConvTranspose2d(channels[3], channels[2], 3, stride=2, bias=True)\n",
        "    self.dense5 = Dense(embed_dim, channels[2])\n",
        "    self.tgnorm4 = nn.GroupNorm(32, num_channels=channels[2])\n",
        "    self.tconv3 = nn.ConvTranspose2d(channels[2] + channels[2], channels[1], 3, stride=2, bias=False, output_padding=1)\n",
        "    self.dense6 = Dense(embed_dim, channels[1])\n",
        "    self.tgnorm3 = nn.GroupNorm(32, num_channels=channels[1])\n",
        "    self.tconv2 = nn.ConvTranspose2d(channels[1] + channels[1], channels[0], 3, stride=2, bias=False, output_padding=1)\n",
        "    self.dense7 = Dense(embed_dim, channels[0])\n",
        "    self.tgnorm2 = nn.GroupNorm(32, num_channels=channels[0])\n",
        "    self.tconv1 = nn.ConvTranspose2d(channels[0] + channels[0], 1, 3, stride=1)\n",
        "\n",
        "    # The swish activation function\n",
        "    self.act = lambda x: x * torch.nn.functional.sigmoid(x)\n",
        "\n",
        "  def forward(self, x, t, coarse=False):\n",
        "    # Obtain the Gaussian random feature embedding for t\n",
        "    embed = self.act(self.embed(t))\n",
        "    if coarse:\n",
        "      x = self.coarse(x.reshape((N,1,int(H*W/4))))\n",
        "\n",
        "    # Encoding path\n",
        "    h1 = self.conv1(x)\n",
        "    ## Incorporate information from t\n",
        "    h1 += self.dense1(embed)\n",
        "    ## Group normalization\n",
        "    h1 = self.gnorm1(h1)\n",
        "    h1 = self.act(h1)\n",
        "    h2 = self.conv2(h1)\n",
        "    h2 += self.dense2(embed)\n",
        "    h2 = self.gnorm2(h2)\n",
        "    h2 = self.act(h2)\n",
        "    h3 = self.conv3(h2)\n",
        "    h3 += self.dense3(embed)\n",
        "    h3 = self.gnorm3(h3)\n",
        "    h3 = self.act(h3)\n",
        "    h4 = self.conv4(h3)\n",
        "    h4 += self.dense4(embed)\n",
        "    h4 = self.gnorm4(h4)\n",
        "    h4 = self.act(h4)\n",
        "    # Decoding path\n",
        "    h = self.tconv4(h4)\n",
        "    ## Skip connection from the encoding path\n",
        "    h += self.dense5(embed)\n",
        "    h = self.tgnorm4(h)\n",
        "    h = self.act(h)\n",
        "    h = self.tconv3(torch.cat([h, h3], dim=1))\n",
        "    h += self.dense6(embed)\n",
        "    h = self.tgnorm3(h)\n",
        "    h = self.act(h)\n",
        "    h = self.tconv2(torch.cat([h, h2], dim=1))\n",
        "    h += self.dense7(embed)\n",
        "    h = self.tgnorm2(h)\n",
        "    h = self.act(h)\n",
        "    h = self.tconv1(torch.cat([h, h1], dim=1))\n",
        "    return h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBeosrNs-M8_"
      },
      "source": [
        "## Train N timestep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "MZKG74QhFc-l",
        "outputId": "7fa1a4fd-8bf8-40c8-c27b-516e54318e0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/20 [00:01<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'R_block' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-3d48c90a33f4>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m####### kernal preserving restriction ####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mR_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_R_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR_block\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;31m####### bilinear interpolation ###########\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mP_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_P_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP_block\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'R_block' is not defined"
          ]
        }
      ],
      "source": [
        "model_score = ScoreNet()\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "optimizer = SGD(model_score.parameters(), lr=1e-2, momentum=0.9)\n",
        "mm_scaler = MinMaxScaler()\n",
        "model_score.train()\n",
        "\n",
        "# we want to sample from random time steps to construct training samples\n",
        "random_t = np.random.rand(N-3)\n",
        "random_t = np.insert(random_t, 0, dt) # first step we want something small\n",
        "random_t = np.insert(random_t, 0, 1)\n",
        "random_t = np.sort(random_t) # we sort the time in increasing order for denoising\n",
        "time_ = np.insert(random_t, 0, eps).astype(np.float32) # for denoising we want time 0 to always be in sample to train\n",
        "sigma_ = diffusion_coeff(torch.tensor(time_), sigma).detach().numpy()\n",
        "\n",
        "# for x,_ in data_loader:\n",
        "data = mnist.data[0]\n",
        "x[0] = torch.tensor(mm_scaler.fit_transform(data.ravel()[:, None]).astype(np.float32)).reshape((1, 1, H, W))\n",
        "kde = KernelDensity(kernel='gaussian').fit(data.ravel()[:, None])\n",
        "m[0] = kde.score_samples(data.ravel()[:, None]) / (2*sigma_[0]**2)\n",
        "del_m[0] = np.diff(m[0].ravel(), axis=0, prepend=m[0,0])\n",
        "\n",
        "for e in tqdm(range(epoch)):\n",
        "  # we normalize for sigma to ensure the dynamics doesn't blow up\n",
        "  A_block = []\n",
        "  for i, t_ in enumerate(random_t, 1):\n",
        "    A = construct_A(dx, dy, t_ - time_[i-1], np.zeros((H, W)), sigma_[i], scores[i], H, W)\n",
        "    if i == 1:\n",
        "      A_block = sp.linalg.block_diag(A)\n",
        "    else:\n",
        "      A_block = sp.linalg.block_diag(A_block, A)\n",
        "      A_block[(i-1)*H*W:i*H*W, (i-2)*H*W:(i-1)*H*W] = -np.eye((H*W))/(t_ - time_[i-1])\n",
        "\n",
        "  B = construct_B(dx, dy, time_[1] - time_[0], m[0], np.zeros((H, W)), sigma_[1], scores[1])\n",
        "  B_block = np.zeros(A_block.shape[0])\n",
        "  B_block[:H*W] = B\n",
        "\n",
        "  # update m (pre-smoothing)\n",
        "  for i, t_ in enumerate(random_t, 1):\n",
        "    A = construct_A(dx, dy, t_ - time_[i-1], np.zeros((H, W)), sigma_[i], scores[i], H, W)\n",
        "    m[i] = gauss_seidel(A, B, m[i])\n",
        "\n",
        "  R = construct_R(int(H/2), int(H))\n",
        "  P = construct_P(R)\n",
        "  R_block = []\n",
        "  P_block = []\n",
        "  for i, t_ in enumerate(random_t, 1):\n",
        "    ####### kernal preserving restriction ####\n",
        "    R_block = construct_R_block(R, R_block, i)\n",
        "    ####### bilinear interpolation ###########\n",
        "    P_block = construct_P_block(P, P_block, i)\n",
        "\n",
        "  # we want to perform the coarse grid\n",
        "  # compute residual r = b - Am[1:]\n",
        "  r = B_block - A_block@m[1:].flatten()\n",
        "  # coursening step 1: r_c = R_c@r\n",
        "  r_c = R_block@r\n",
        "  # coursening A_c = R_c@A@P_c (Petrov-Galerkin Coursening)\n",
        "  A_c = R_block@A_block@P_block\n",
        "  # compute course err: err_c = solve_pde(A_c,r_c)\n",
        "  err_c = solve_pde(A_c, r_c, mode='sparse')\n",
        "  # interpolate to fine grid: err = P_c@err_c\n",
        "  err = P_block@err_c\n",
        "\n",
        "  # we apply fine grid-correction\n",
        "  m[1:] = (m[1:].flatten() + err).reshape((N-1, H*W))\n",
        "  # update m (post-smoothing)\n",
        "  for i, t_ in enumerate(random_t, 1):\n",
        "    A = construct_A(dx, dy, t_ - time_[i-1], np.zeros((H, W)), sigma_[i], scores[i], H, W)\n",
        "    m[i] = gauss_seidel(A, B, m[i])\n",
        "  # m[1:] = solve_pde(A_block, B_block).reshape((N-1, H*W)) # uncomment for finite difference solution\n",
        "  m_c[1:] = (R_block@m[1:].flatten()).reshape((-1, int(H*W/4)))\n",
        "\n",
        "  # constructing the training data and labels\n",
        "  for i, t_ in enumerate(random_t, 1):\n",
        "    del_m[i] = np.diff(m[i].ravel(), axis=0, prepend=m[i, 0]) #/ (2*sigma_[i]**2)\n",
        "\n",
        "  x = torch.tensor(mm_scaler.fit_transform(np.exp(-m).ravel()[:, None])).reshape((N, 1, H, W))\n",
        "  perturbed_x = x + torch.randn_like(x) * torch.sqrt(2 * torch.tensor(sigma_)**2)[:, None, None, None]\n",
        "  print(perturbed_x.max(), perturbed_x.min(), del_m.max(), del_m.min())\n",
        "  train_x_data = perturbed_x\n",
        "  train_y_data = torch.tensor(del_m.astype(np.float32)).reshape((N, 1, H, W))\n",
        "\n",
        "  # plt.imshow(train_x_data[-1].detach().numpy().reshape((H, W)))\n",
        "  # plt.show()\n",
        "\n",
        "  # plt.imshow(train_y_data[-1].reshape((H, W)))\n",
        "  # plt.show()\n",
        "\n",
        "  x_c = torch.tensor(mm_scaler.fit_transform(np.exp(-m_c).ravel()[:, None])).reshape((N, 1, int(H/2), int(W/2)))\n",
        "  perturbed_xc = x_c + torch.randn_like(x_c) * torch.sqrt(2 * torch.tensor(sigma_)**2)[:, None, None, None]\n",
        "  train_xc_data = perturbed_xc\n",
        "\n",
        "  yc_pred = model_score(train_xc_data, torch.tensor(time_), coarse=True)\n",
        "  lm = (2*torch.tensor(sigma_)**2)[:, None, None, None]\n",
        "  loss = loss_fn(yc_pred / lm, train_y_data)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  losses = loss.item()\n",
        "\n",
        "  y_pred = model_score(train_x_data, torch.tensor(time_))\n",
        "  lm = (2*torch.tensor(sigma_)**2)[:, None, None, None]\n",
        "  loss = loss_fn(y_pred / lm, train_y_data)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  losses = loss.item()\n",
        "\n",
        "  scores = (y_pred / lm).clone().detach().numpy().reshape((N, H, W)) # we normalize before fedding back into PDE\n",
        "\n",
        "  plt.imshow(scores[0].reshape((H, W))) # so we can see that the score should look something like this after training\n",
        "  plt.show()\n",
        "\n",
        "torch.save(model_score.state_dict(), 'ckpt.pth')\n",
        "print(f\"\\nmodel has been saved\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57nhZU8trGp5"
      },
      "source": [
        "# Solving the ODE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Lq7obwO-cOEv"
      },
      "outputs": [],
      "source": [
        "#@title ODE functions\n",
        "\n",
        "from scipy import integrate\n",
        "\n",
        "## The error tolerance for the black-box ODE solver\n",
        "def ode_sampler(score_model,\n",
        "                diffusion_coeff,\n",
        "                batch_size=64,\n",
        "                z=None,\n",
        "                eps=eps):\n",
        "  \"\"\"Generate samples from score-based models with black-box ODE solvers.\n",
        "\n",
        "  Args:\n",
        "    score_model: A PyTorch model that represents the time-dependent score-based model.\n",
        "    marginal_prob_std: A function that returns the standard deviation\n",
        "      of the perturbation kernel.\n",
        "    diffusion_coeff: A function that returns the diffusion coefficient of the SDE.\n",
        "    batch_size: The number of samplers to generate by calling this function once.\n",
        "    device: 'cuda' for running on GPUs, and 'cpu' for running on CPUs.\n",
        "    z: The latent code that governs the final sample. If None, we start from p_1;\n",
        "      otherwise, we start from the given z.\n",
        "    eps: The smallest time step for numerical stability.\n",
        "  \"\"\"\n",
        "  # Create the latent code\n",
        "  if z is None:\n",
        "    init_x = torch.randn(batch_size, 1, H, W) # * torch.sqrt(2 * diffusion_coeff(torch.ones(batch_size, 1, H, W), sigma)**2)\n",
        "  else:\n",
        "    init_x = z\n",
        "\n",
        "  shape = init_x.shape\n",
        "\n",
        "  def score_eval_wrapper(sample, time_steps):\n",
        "    \"\"\"A wrapper of the score-based model for use by the ODE solver.\"\"\"\n",
        "    sample = torch.tensor(sample, dtype=torch.float32).reshape(shape)\n",
        "\n",
        "    time_steps = torch.tensor(time_steps, dtype=torch.float32).reshape((sample.shape[0],))\n",
        "    with torch.no_grad():\n",
        "      score_ = score_model(sample, time_steps)\n",
        "  # plt.imshow(score_.reshape((H, W)))\n",
        "  # plt.show()\n",
        "    return score_.cpu().numpy().reshape((-1))\n",
        "\n",
        "  def ode_func(t, x):\n",
        "    \"\"\"The ODE function for use by the ODE solver.\"\"\"\n",
        "    # time_steps = np.ones((shape[0],)) * t\n",
        "    g = diffusion_coeff(torch.tensor(t), sigma)\n",
        "    return  -0.5 * (g**2) * score_eval_wrapper(x, t)\n",
        "\n",
        "  # Run the black-box ODE solver.\n",
        "  res = integrate.solve_ivp(ode_func, (1., eps), init_x.reshape(-1))\n",
        "  print(f\"Number of function evaluations: {res.nfev}\")\n",
        "  sol = res.y[:, -1].reshape(shape)\n",
        "  return sol"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD7afJFaqgfg"
      },
      "source": [
        "## Sample ODE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bt6sKAOTcA1z"
      },
      "outputs": [],
      "source": [
        "from scipy import integrate\n",
        "\n",
        "ckpt = torch.load('ckpt.pth')\n",
        "model_score.load_state_dict(ckpt)\n",
        "model_score.eval()\n",
        "\n",
        "sample_batch_size = 1 #@param {'type':'integer'}\n",
        "sampler = ode_sampler #@param ['ode_sampler'] {'type': 'raw'}\n",
        "\n",
        "# init_x = perturbed_x[-1].reshape((sample_batch_size, 1, H, W))\n",
        "\n",
        "## Generate samples using the specified sampler.\n",
        "samples = sampler(model_score,\n",
        "                  diffusion_coeff,\n",
        "                  sample_batch_size)\n",
        "\n",
        "plt.imshow(samples.reshape(H, W), cmap = 'gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yoq-u0qZSVNS"
      },
      "source": [
        "# Tutorial on Diffusion Models\n",
        "\n",
        "tutorial on diffusion model can be found on https://colab.research.google.com/drive/1d2-L9uPKQNqZcgpK7CZzhHrCmwQsz5BC?usp=sharing\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "QERPscoSrIzG",
        "3D45yl1drKub",
        "9iv4QhuvJNmm",
        "_IchHH39yXca"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}